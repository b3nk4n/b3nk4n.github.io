[ { "title": "Apache Kafka and the Page Cache", "url": "/posts/kafka-page-cache/", "categories": "Software Engineering", "tags": "linux, kafka, streaming", "date": "2024-11-27 00:00:00 +0100", "snippet": "At Instana, we use Apache Kafka as our distributed event streaming platform. Due to the growing adoption of the product, the amount of data flowing through our Kafka brokers more than doubled compared to last year. Exceeding 12 GB/s ingress across five production regions on AWS and GCP.As part of the investigation about bad latency of individual consumers, I had to dive deep into the topic of Kafka performance optimizationand how Kafka achieves its performance. And after we could correlate the bad latencyand growing message lag to spikes in the read utilization of the underlying disks, we especially focused on how Kafka utilizes the disks and memory.And one interesting learning of this journey was how Kafka takes advantage of the OS page cache.What is the OS page cache?The page cache of the operating system is a transparent caching layer for the pages from the secondary storage devices (SSD, HDD). Unused main memory is used as a cache for pages to allow faster access and overall performance improvements. This caching layer is so transparent thateven most Software Engineers don’t now about it. And you don’t even see it when you check you memory usage of your host, such as via htop:Memory usage using htop: Actually more than 9.31GB of memory are in active useThe shown memory usage is only representing the proportion of memory utilized by processes. However, it does not include the amount of memory transparently usedfor the OS page cache. On Linux, you can show the overall memory usage using the command free -m:$ free -m total used free shared buff/cache availableMem: 31496 9794 1002 0 20699 21382Swap: 0 0 0This tells us that: From the total 32GB of memory, only about 1GB is unused (free). The operating system is using about 20GB of main memory as page cache (buff/cache). We are not using any swap memory, which is generally disabled on this system.Are swap memory and page cache the same thing?While both have in common that they relate to memory management, the swap memory is a dedicated portion of a hard disk used to store inactive data from main memory when it is full. Essentially extending the available memory. In contrast, the page cache is a part of the main memory where frequently accessed file data is stored temporarily to improve performance by reducing disk reads.In other words, swap memory is used when the RAM is full, or when pages are stale, such as due to inactive processes 1. Whereas the page cache is used to speed up access to frequently used files from the disk.What did we learn?When using Kafka at scale, memory really matters. And that is true even when your monitoring tool of choice might tell you that memory utilization is low.From my experience, when working in context of a high throughput application, it is also important to keep an eye on the read utilization of the underlying disk. Ideally, you will never read from disk, unless you are restarting any of the consumers that need to catch up. Otherwise, a many reads to the disk mightindicate some sort of problem, such as that a consumer is continuously lagging behind. Which might be either because your consumer cluster is under-scaled,or because your Kafka nodes are overloaded. In case it is the latter, it is worth checking whether there is an imbalance within your Kafka cluster, such as by checking the partition assignment using: $ /opt/kafka/bin/kafka-topics --describe --topic &lt;topic-name&gt; --bootstrap-server localhost:9092In some cases, manually triggering leader election or to reblanace the cluster might already do the job. However, if you have a dominating topicwhich has a significantly higher throughput compared to other topics, then it will make sense to ensure that the partitions of that topic areequally balanced across the Kafka cluster.Instana dashboard widget of a Kafka Cluster showing a dominating topicOtherwise, correlating metrics of the Kafka broker’s disks with metrics in the consumers might also reveal interesting patters.Instana custom dashboard widgets of metrics about disk read utilization in the Kafka nodes, and the consuming stream processorOnce you see disk reads, such as in the image above during peak hours, you might be able to correlate this to a degradation in the fetch-latency of your consumers. This increase in latency can cause message lag, which might lead to dropping in your stream processors to catch up,in case this situation is handled the same way as when having to drop data due to backpressure. All of this is under the assumption that your problem domainallows you to drop data. Otherwise, (auto) scaling the consumers, such as using KEDA, would be an alternative way of handling this situation.Lastly, it is good to be aware that an under-scaled consumer of a topic can have a negative impact on the overall Kafka cluster. If consumers of a specific Kafka topic are continuously lagging behind, that means the likelihood that the request needs to be served from disk is higher compared to when fetching more recent data. Of course, all of that depends on your configured Kafka topic configuration, such as via log.retention.ms or log.retention.bytes, and the throughput of data in contrast to the available page cache.How are the topic partitions of a Kafka log utilizing the page cache?On our journey of tweaking our Kafka cluster and resolving performance bottlenecks, one tool that came in handy was vmtouch.The Virtual Memory Toucher is a tool for peeking into the file system cache of unix and unix-like systems.Using that tool, we could get a better idea how much of the Kafka message log could be served from page cache. Furthermore, we could get a better idea abouthow much consumer lag could be served from memory due to the page cache. And about what consumer lag is more likely serviced from disk and explain the highread utilization we have been seeing.Using vmtouch to show details about the page cache usage of a single Kafka partitionConclusionUnderstanding the page cache is fundamental when working with Kafka, because it’s one of the main aspects which makes it so far.Furthermore, when operating Kafka at scale, it is important to also keep an eye on the disk utilization, beside just CPU and memory.Especially the read utilization of your disks. And don’t get fooled if your memory only seems to be utilized by less than 50%.The number you are looking at is very likely not incorporating the page cache.Ideally, use your observability tool of choice, and if not done already out-of-the-box, define an appropriate alert to uncover this situation proactively. Related to Kafka, see the section about vm.swappiness in this post or in Tuning Virtual Memory. &#8617; " }, { "title": "Resolve Read-only Device Access", "url": "/posts/resolve-read-only-device-access-copy/", "categories": "Tools", "tags": "mac, linux, trick", "date": "2024-01-09 00:00:00 +0100", "snippet": "On your MacBook (or Linux based device), external devices such as hard drives or SD cards might be mounted by default as read-only.This could be due to different reasons, such as enforced by a device policy:Permission: You can only readHowever, if you need write access to that device to back up your data or similar, there is a simple workaround to resolve that.By manually mounting the disk manually with both read &amp; write access.1. Find the respective deviceAny of the following CLI tools might help you to find the device or mount point of the device you are looking for:df -hdiskutil list2. Unmount the deviceAssuming the device is called /dev/disk7s1 with mount point /Volumes/sdc and uses FAT32 (like my SD card),then use either of the following command to unmount it first:sudo umount /Volumes/sdcdiskutil unmount /dev/disk7s13. Manually mount the device with read &amp; write accessFinally, mount it once again, but with custom permissions:sudo mkdir /Volumes/sdcsudo mount -o rw -t msdos /dev/disk7s1 /Volumes/sdcPlease note that -o rw is the option to enable both read and write access, and -t msdos defines the filesystem type to be FAT32.Permission: You have custom accessChecking the device permissions once again reveals that the mention of “You can only read” is gone. Great!" }, { "title": "Record Your Terminal With Terminalizer", "url": "/posts/record-your-terminal-with-terminalizer/", "categories": "Tools", "tags": "terminalizer, terminal, console, recording", "date": "2022-04-04 00:00:00 +0200", "snippet": "Did you ever want to demo a terminal program or remotely explain a sequence of commands to a friend or colleague?If so, then terminalizer is a tool for you…Example recording with terminalizerInstallationWhile the installation steps described in the docs are not very detailed.When simply followed them, I ended up with errors. It turned out that Node.js 16 is notyet supported. Consequently, I needed to switch to an older version to run this successfully.Consequently, the following sequence of command did the trick.$ nvm use 14$ npm install -g terminalizerNext, as a Mac user with oh-my-zsh, I created and edited a config.yaml to run zsh instead of the default bashin the recoreded terminal to effectively get the themese applied in the recording.$ terminalizer init$ vim ~/.terminalizer/config.yamlWithin the config file, set the command from null to zsh. Because the ZSH_THEME=\"agnoster\" that I usually use has a minor rendering glitch. In the example above,the more simplistic theme ZSH_THEME=\"robbyrussell\" is used instead.UsageThe commands for basic usage are explained in detailed in its docs.However, the most common commands are the following: terminalizer record &lt;name&gt;: Started a recording and saves a &lt;name&gt;.yaml file. terminalizer play &lt;name&gt;: Play a recording in the terminal. terminalizer render &lt;name&gt;: Renders a GIF using the given recording. In case you ever end up a warning such as zsh: command not found: terminalizer after installing and using terminalizersuccessfully, then check your Node version with node -v. At the time of writing, there seem to be troubles with v16.13.1,but no issues with v14.17.0." }, { "title": "Quick Data Visualization in Python", "url": "/posts/quick-data-visualizaiton-in-python/", "categories": "Data Visualization", "tags": "python, matplotlib, plotly, termgraph, plotext, uniplot, tabulate, data, visualization", "date": "2022-04-03 00:00:00 +0200", "snippet": "In in previous post, I wrote about Matplotlib as a must have tool on your system to dointeractive data visualization in an instant.Today, I worked on a playground project called b3nk4n/quick-data-visualizationwhere I started to collect and compare a few Python plotting libraries using a small set of data, such a nestedPython list, a time-series in form ofa NumPy array and a Pandas dataframe.At least the following plotting libraries are covered:UI-based matplotlib plotlyText-based python-tabulate uniplot termgraph plotextTo give you an idea, the following recording should serve as an example.Python quick data visualization in actionPersonally, I sill prefer Matplotlib over Plotly, mainly because it opens in a window instead of in a web browser by default.However, Plotly’s interactivity is definitly more powerful compared to Matplotlib, by offering features such as mouse-overoverlays. I really hope that some of these concepts end up in Matplotlib one day.Regarding the text-based libraries, I really like Plotext because it almost works as a drop-in replacement for Matplotlib dueto the use of a very similar API. I’m very sure this was not by accident." }, { "title": "Retrospective on 6 Years of Windows App Development", "url": "/posts/windows-app-dev-retro/", "categories": "Projects, Analytics", "tags": "windows, windows phone, downloads, review, history", "date": "2022-03-23 00:00:00 +0100", "snippet": "This article is a follow-up on previous posts about reaching individual milestones on my journeyas an Indie Window App Developer: 100k Downloads in Windows Phone Store — 05/2013 250k Downloads in Windows Phone Store — 10/2013 500k Downloads in Windows Phone Store — 09/2014 1 Million Downloads in Windows App Store — 05/2015IntroAbout 5 years have passed in the meantime after I submitted my last update to any of my Windows 10 (Mobile) apps.This is more or less right after I finished my Masters degree. My focus simply shifted towards other things,such as work, other side projects such as games for Android using LibGDX.Or even non-professional things such as hiking, reading criminal novels — I really ♥ books from Jo Nesbø —or last but not least spending quality time with my wife and friends.Anyways, a lot happened in the meantime. And I’m not talking about the pandemic or the war in Ukraine. I’m referring to much lessimportant things such as the fact that Microsoft ended support for Windows 10 Mobileend of 2019. And that was my main target platform as a developer back then. With the exception of Action Note,Windows 8 and later Windows 10 was just secondary.Action Note with innovative Action Center integration — launched in late 2015To be very honest, after not supporting or updating my apps and game for such a long time, the main reason that triggeredhaving a closer at them once again is kind of embarrassing: Microsoft started to unpublish one app after the other due tomy inactivity. The following is from Microsoft’s report: App Policies: 10.1.4 App Quality - Active Presence Notes To Developer Apps must have an active presence in the Store. When determining this Microsoft looks for several factors includingacquisitions rate and update frequency.Because I’m neither owning a Windows powered smartphone nor laptop anymore, I think it’s time to unpublish the majorityof the apps that might not fully work anymore for various reasons, such as changes in 3rd party APIs, changes in theWindows APIs or policies like the Action Center, etc. I’m sure the most recent app reviews will serve as a very goodheuristic for that.Why did I start to develop for Windows Phone?How did I actually end up developing apps and games for Windows Phone 7, Windows 8 any beyond you might ask? Wasn’t italready said to be without any real chances against Apple’s App Store or Google’s Play Store dominance?Well, that’s absolutely right. And it was more or less by accident in the end.Everything kind of started with a mini job as a Junior .Net Developer that I started in 2009. There, I created a firstprototype for the mobile client of a task tracking application called QuickTask. Windows Phone 7 was not even publiclyavailable yet, so the development and debugging of it was purely based on an early version of a Window Phone simulator.With a little bit of luck and good connections, we have been invited by Sascha Cortito Microsoft Zurich one day to run our app on an early LG prototype of a Windows Phone 7 device. I still remember howthick that device was. Very close to a Nokia 3310. All that clearly influenced mequite a bit as somebody who did not even yet start his first semester at university.But I was short on money. And any smartphone has still too expensive for me to even think about buying one.And it took even more luck before I finally start with my indie dev career. If you can even call that a career? More a hobby?Anyways, I think somewhen in late 2010 or early 2011, I participated at a conference calledMicrosoft Shape in Zürich. And withineach bigger break, there have been quizzes with the audience. Actual exactly three in total. The moderator just droppeda question into the about 400+ people large audience. And the first one shouting out the right answer got a prize. And guesswhat the prizes has been? Exactly, an LG Optimus 7, one of the firstWindows Phone 7 device on the market. And if I remember correctly, such devices have been launched just a few weeks beforethat conference. And who was lucky (or smart) enough to walk home with two of these WP7 devices? Me! ㋡The very start of my 2D game dev journeyThe rest was then just my pure ambition to put my ideas and things I learned at university, by reading articles or booksinto practice. I liked playing video games. And many of the projects in the first semester have been rather boring for me,because I already had many years of programming experience compared to most of the others. And I felt a little but unchallenged.Consequently, I started to put most of my time outside of my lectures into my own projects instead. I started to read a bookabout XNA, which taught the basics of game development using the example ofa very primitive space shooter. Guided with the book, I implemented it. Then extended it a little bit. And was hooked.Out of nowhere, I had so many ideas how to extend that game. Different types of weapons and enemies. Particle effects. Creatingmy own pixel art. Online leaderboards. Accelerometer controls. I had such a rush of adrenalin, that worked on my project till 8amin the morning, then went to my lectures and finally took a power nap during the lunch break to recharge. Just a few weeks later,my first game SpacepiXX was born.First version of SpacepiXX — launched in April 2011The next games AstropiXX andVaderpiXX have been reusing 90% of the underlyingcode base. Followed by SpaceScribble in which Iexperimented with an all-hand-drawn game experience. And it was a huge success. Just a few days after its release, watchingthe DevCenter stats like an addict, I was absolutely amazed and could almost not believe it when I’ve seen a huge spike in thenumber of downloads. Far more than 10,000 downloads in just a single day. Without putting a single cent into advertisement.I knew something must have happened. And a quick Google search could answer that. WPCentral, the most renowned Windows Phonerelated website I’m aware of, wrote an extensive and positive article about my game calledSpaceScribble, Windows Phone space combat the doodle way.SpaceScribble review by WPCentral in March 2014Transition to app developmentAfter diving deep into game development for almost two years, I realized that there was a lot of overhead necessarily with developinggames, such as taking care of all the required graphics, game design and sound effects. The background music always has beenthe only thing where I borrowed the help from friends, such as this blasting theme remix used in VaderpiXX byQBIG who I know since preschool. To have some variety, I decided to develop aregular app next. Nothing too fancy, but practical. And because the canteen of my university had an Android but no Windows Phoneclient yet, I implemented seeMENSA to provide the menufor any university around Lake Constance.Next, and during my exchange semester at WPI in the US, I wanted to work on a tool to make my ownpower napping more convenient. The default clock app in Windows Phone 7.5 was not really convenient, and it took many tapsin order to setup a short 30-minute alarm. When I felt like I could fall into sleep right now for a nap, navigating to the clockapp and setting the timer ripped me out of my napping mood, and it took me too long to get back into it. So, I decided to implementan app to make setting the napping timer as quick as possible. The idea forpowernAPP was born. And with the introduction ofCortana and the hype around voice-controlled apps, I found a way toset a napping timer without even a single tap: just by using natural language such as “Power nap for 20 minutes” instead.And was another hit.The feedback by users was overwhelming. At some point, I received about 10 email per week from users that asked for featurerequests or just wanted to share how much they enjoyed my free apps. And on top of that, there have also been hundreds of reviewsin the Windows Store.Complex apps with lots of functionalities have never been a thing for me. I liked it a lot when an app had a small scope,but did that thing just right. And tried to apply the same thing to my own apps by focusing on creating small tools fora specific purpose that made the life of a user at least a tiny bit simpler. One good example for that isPhoto Marker, which was later also reviewedby Windows Central. It integrated into the Windows Phoneoperating system to easily add annotations to a picture right before sharing it with another app. This was even way before WhatsAppadded the annotation feature to their app.Photo Marker review by Windows Central in December 2014Entering the era of Universal Windows PlatformThe last app I want to talk about is Action Note,which was – guess what – also reviewed by Windows Central in a review calledNote-taking made easy with Action Note for Windows 10 PC and Mobile.I found many of the popular note-taking apps to complex and cluttered with features I did not need. And ever since theAction Center was introduced in Windows 10 Mobile and PC, I was looking for an app which integrates well with it.After I realized nothing like that exists, I decided to develop it myself. Including cross-device synchronization as a premiumfeature. This external video review demonstrates is quite well.And even though it’s by far not my most downloaded app, it was in the end the major cash cow with an extraordinary conversion rate.About 2% of the users decided to upgrade to the Pro version of the app to unlock the cross-device syncing. That’s extremely high!Especially because it was not just a 0.99$ IAP, but my only every premium feature where I set a high price tag of 3.99$.Action Note review by Windows Central in December 2015But users loved it. Not just Action Note. The positive feedback from users and their constructive support was overwhelming.They asked for internationalization, but I did not want to spend money on a translator. So, users started to volunteer to helpme with i18n. And ended up with apps that have been available in 19 languages: Arabic Chinese (Simplified) Chinese (Traditional) Czech Dutch English French German Hebrew Hungarian Italian Korean Polish Portuguese Portuguese (Brazil) Spanish Swedish Turkish UkrainianAnd because not many apps are available in some of these languages, even popular ones, this gave me just another big boostthanks to that great community. And with that help, I even managed to have multiple of my apps being listed in the top 20for multiple weeks. Or took over the pole position from Runtastic as the best Health &amp; Fitness appin the Windows Phone Store for quite some time, which was more than hilarious.3 of my apps listed in the top 20 highlights of the Windows Phone StoreRetrospectiveNow, about 5 years after I wrote my last line of C# code, I would like to do a tiny look back into what worked pretty well,and what I could have done differently.The good Even though Windows Phone never had a market share bigger than 5% globally, probably not even close, it was still a gooddecision to develop for Windows Phone at that time. And I’m very sure I would have never reached such a big audience on iOSor Android. Simply because on both platforms, it is very hard to get visibility without investing money first.In contrast, at least in the first years of Windows Phone, every single new app was listed at the very top in the Windows Storein a special New Releases section. Which immediately generated downloads and visibility from day one. The focus on small and simply apps helped me not just to create many of them, but also made it easier to guarantee goodquality, make them easy to use and iterate on feedback quickly. Providing apps in various languages had a very good effect to get better visibility in respective markets and finally increasethe number of downloads. Especially as a beginner in the early days, starting with an example such as a tutorial from a book, and then extending itstep by step with your own ideas to an entire tiny product worked very well. The freemium model is the perfect model for your apps as an indie developer.Don’t bother about even thinking about setting a price tag for your app. Instead, if you have features users might want tospend money on, use in-app products. Otherwise, users will very likely simply not even download your app. And all your timeand effort was for nothing. Keep a close eye on user reviews. Engaging with users via contact form or app store reviews helped to spot bugs,deliver features or improvements users really cared about. And helped me to keep my motivation on a high level overmany years. I can recommend every programming beginner to start with game development. Also for programming lectures at university.It makes topic much more exciting. In my Bachelors, about 50% of the students didn’t make it till the 3rd semester. Whilethis was on one side due to quite challenging math exams, it was on the other side because many of them gave up with learning tocode. Many of them could not really relate to boring terminal applications which ask for your age, or writing data strucutres such aslists or sets. I’m pretty sure most of them would not have given up in case we would have started to write simple 2D gameswithin the first two semesters. And from the topic we learned, they should have been able to do so. At least in my point of view, one important skill I learned on this journey is to look at a product from both a technical but stillrelatively neutral or unbiased user perspective. I was in direct conversation with customers over many years, and basically acted inall roles such as Product Manager, Customer Success, Software Engineer and Tester. This skill is something I found very useful in myprofessional career. At least I have the feeling that I have a much better sense of good UX, product consistency and spotting bugscompared to the average Software Engineer.The bad Localization of your app has positive effects, but please wait until you have a stable version with all the major features implemented.Trust me, if you rely on volunteers to translate your app, then you don’t want to end up in a situation where you cannot add new features justbecause you are not able anymore to translate it into all the supported languages. This can slow you down quite a lot. At some point a started to add ads to some of my apps or games. But I regret doing this. At least regular ad banners really destroy theuser experience of your app. But I might be a bit biased here. If I could travel back in time, I would have spent more time reading into topics around cross-platform development. It is a bit unfortunate that only a minority of my friends could actually use any of my apps, because most of them have been obviouslyAndroid or iOS users. However, I’m still pretty sure that I would not have had such a success on these platforms.AnalyticsLet’s have some fun with numbers together.Downloads and ratingsTo have a final summary of my downloads, app ratings and reviews, I collected the data from Microsoft Partner Centerand composed the following table. # App / Game Total downloads ★ Rating [1 – 5] User reviews 1 Photo Marker 832,556 4.4 ★ 5,575 2 powernAPP 643,637 4.5 ★ 6,778 3 SpaceScribble 248,480 4.6 ★ 2,080 4 Action Note 159,500 4.4 ★ 1,548 5 Whip 121,263 3.9 ★ 2,116 6 AstropiXX 104,570 3.4 ★ 382 7 SpacepiXX 89,299 3.8 ★ 625 8 Photo Info 79,816 4.5 ★ 1,472 9 pocketBRAIN 68,201 4.5 ★ 1,808 10 Daily Focus 27,835 3.6 ★ 134 11 ScribbleHunter 20,801 4.4 ★ 161 12 Pin to Start 14,986 4.5 ★ 147 13 URI Launcher 13,203 3.9 ★ 40 14 Frequenzer 12,110 4.6 ★ 271 15 VaderpiXX 8,244 3.5 ★ 33 16 Voice Timer 4,194 4.6 ★ 114 17 Bash0r 2,995 3.3 ★ 15 18 ScribbleHunter Pro 2,351 4.0 ★ 17 19 seeMENSA 2,155 4.6 ★ 73 20 iBash0r 611 4.4 ★ 23 21 German Bash0r 609 4.7 ★ 6 22 Developer’s Diary 402 4.6 ★ 9 23 PriceChecker 244 3.7 ★ 6 24 UWPCore 5 - -     2,458,067 4.4 ★ 23,433 I have to admit, I’m more than surprised that the average rating is still far above 3 ★ even 5 years after I stopped supportingmy apps and games. That being said, there are many 1 ★ reviews within the last years for quite a few apps, because some of themare not fully functional anymore. As an example, the Action Center API and usage regulations changed, and thereforeAction Note’s key feature does not work anymore. But still, its average rating is 4.4 ★, and was previously even very close to4.8 ★, which is absolutely amazing.Furthermore, when I started with my first game in 2011, I would have never dreamed of ever getting close toabout 2.5 million downloads. And receiving such good reviews by more than 23,000 users.Activity since I stopped supporting my appsAfter I published my very last app update in early 2017, Microsoftannounced end of supportfor Windows 10 Mobile in December 2018. And finallyended its supportone year later. I thought it would be interesting to see how this influenced things such as downloads or activityin the Windows Phone store. This is shown in the following images.As a first example, I exported the data since around 2016 from Microsoft Partner Center. Unfortunately, no data beforethat could be exported.Photo Marker cumulative downloads since 2016Photo Marker store activity since 2016Taking Photo Marker as an example, my most popular app regarding total app downloads, you can clearly see that app downloadsstarted to stagnate in mid 2018. Starting with the announcement for end of support for Windows 10 Mobile, also the store trafficdropped down to an insignificant amount.powernAPP cumulative downloads since 2016powernAPP store activity since 2016Secondly, the same picture repeats for powernAPP. With the only difference that the store traffic already converged to zeroabout a year earlier. This app was first published in December 2013 and already more than 4 years old at that time.So no big surprises.Action Note cumulative downloads since 2016Action Note store activity since 2016Finally, let’s use Action Note as a second example. This app is availalbe in both Windows 10 Mobile and PC, and thereforea bit different compared to both apps above. Here we can see that app downloads are still happening. Even thoughthere does not seem to be any significant store traffic anymore since mid of 2020.In-app purchases and premiumsFinally, also a few stats about monetization, listed in the following table. App / Game IAPs Purchase of Pro version Action Note 3,111 - Photo Marker 2,540 - powernAPP 1,766 - Photo Info 1,000 - pocketBRAIN 601 - Daily Focus 257 - Whip 66 - ScribbleHunter Pro - 29   9,341 29 Unfortunately, I could not manage to gather the full picture about ad related data, such as impressions, eCPM or revenue.Microsoft seemed to have moved that from Microsoft Advertising, then to Microsoft PubCenter and finally to Microsoft Partner Center.However, in neither of them I can find ad network related information anymore.Last but not least, I want to add that money was never the main driver why I implemented all these apps and games at first place.It for sure helped me to stay motived, but in the end, I just wanted to bring my ideas into reality and apply whatever I have learned so far.However, all that money I earned as an alternative to a student job helped me to finish my studies without having torely heavily on money from my parents (who still sponsored me to pay half of my rent) or a student loan.And together with my scholarship, I earned just enough to pay for my tuition, living cost and other hobbies.SummaryThis this post, I’m closing my chapter of Windows App Development. I kind of did that already 5 years ago, but writing down thesewords make it at least official for me. Within the next days, I will probably unpublish the majority of my apps. At least the oneswhere the users reported in latest reviews that it is not fully functional anymore. Also, I will move the code for each of them frommy private BitBucket to my GitHub account as public repositories. Maybe the source code of these appsor games that have been used by millions of users might be helpful for at least somebody.Thank you for reading this unusually long article!I hope you enjoyed read as much as I enjoyed writing it." }, { "title": "Sharing Command-line Options in Python Argparse", "url": "/posts/sharing-command-line-options-python-argparse/", "categories": "Software Engineering", "tags": "python, argparse", "date": "2021-04-03 00:00:00 +0200", "snippet": "This is probably no big news that argparse makes it easy to writeuser-friendly command-line interfaces. It comes out-of-the-box and is therefore the standard tool if you createa CLI tool in Python.Basic usage of argparseThe following snippet shows a basic usage example of argparse with a single param argument that can be passed tothe command line.import argparsedef main(argv): print(argv.param)if __name__ == '__main__': parser = argparse.ArgumentParser() parser.add_argument('--param', type=int, default=64, help='The param value. Default is 64.') args = parser.parse_args() main(args)This optional argument can then be used used by appending --param VALUE when executing script.$ python argparse_example.py --param 128Introducing subparsersI recently used subparsers for the first time that might not bevery commonly known. Many CLI tool’s split up their functionality into a number of sub-commands. For instance, the git programcan invoke sub-commands like git init, git clone, or git pull. And this is exactly where subparsers come in handy.Basic usage of subparsersThe following code snippet shows a basic usage example of subparsers by defining a single command.import argparsedef command_main(argv): print(argv.param, argv.verbose)if __name__ == '__main__': parser = argparse.ArgumentParser() parser.add_argument('--verbose', type=bool, default=True, action=argparse.BooleanOptionalAction, help='Enable or disable verbosity. Default is True') parser.set_defaults(func=lambda argv: parser.print_help()) subparsers = parser.add_subparsers() command = subparsers.add_parser('command') command.add_argument('--param', type=int, default=64, help='The param value. Default is 64.') command.set_defaults(func=command_main) args = parser.parse_args() args.func(args)This adds a single sub-command called command that has one optional --param parameter. Using the parser.set_defaults(…)on the root parser, we define that the help page is printed when no command is given at all. Furthermore, we also define a--verbose parameter, which needs to be specified before the command. Consequently, a usage example could look like thefollowing.$ python subparsers_example.py --no-verbose command --param 128Sharing arguments between subparsersThe same way as above, you can obviously add multiple commands.import argparsedef init_main(argv): print(argv.param, argv.verbose)def start_main(argv): print(argv.param, argv.verbose)if __name__ == '__main__': parser = argparse.ArgumentParser() parser.set_defaults(func=lambda argv: parser.print_help()) subparsers = parser.add_subparsers() init = subparsers.add_parser('init') init.add_argument('--param', type=str, required=True, help='The required param value.') init.set_defaults(func=init_main) start = subparsers.add_parser('start') start.add_argument('--param', type=str, required=True, help='The required param value.') start.set_defaults(func=start_main) args = parser.parse_args() args.func(args)This basically enables you to have multiple entry points to your script. Great!However, as you can see, we ended up with redundantly defining a single param used in both commands twice. Well, you might thinkwe could simply move it to the root parser. However, this would have the effect that the user needs to define this parameterbefore the command, such as python shared_args_example.py --param value init. But what if you would like to have these paramsafter the command as in python shared_args_example.py init --param value?Fortunately, this is possible by using a shared argument parser as shown in the following snipped.subparsers = parser.add_subparsers()shared_parser = argparse.ArgumentParser(add_help=False)shared_parser.add_argument('--param', type=str, required=True, help='The required param value.')init = subparsers.add_parser('init', parents=[shared_parser])init.set_defaults(func=init_main)start = subparsers.add_parser('start', parents=[shared_parser])start.set_defaults(func=start_main)By defining a separate argument parser via argparse.ArgumentParser(add_help=False), you can define common parameters and sharethese between different subparser commands using the parents param.Putting everything togetherFinally, putting everything togehter, the following can be used as a copy-paste template for any new script or CLI toolthat you are building using Python.import argparsedef first_command(argv): passdef second_command(argv): passif __name__ == '__main__': parser = argparse.ArgumentParser() parser.add_argument('--root', type=bool, default=False, action=argparse.BooleanOptionalAction, help='Enable or disable the root param. Default is False') parser.set_defaults(func=lambda argv: parser.print_help()) subparsers = parser.add_subparsers() shared_parser = argparse.ArgumentParser(add_help=False) shared_parser.add_argument('--shared', type=str, required=True, help='The required shared param value.') cmd1 = subparsers.add_parser('first-command', parents=[shared_parser]) cmd1.add_argument('--local-int', type=int, default=64, help='The local int param value. Default is 64.') cmd1.set_defaults(func=first_command) cmd2 = subparsers.add_parser('second-command', parents=[shared_parser]) cmd2.add_argument('--local-float', type=float, default=1.23, help='The local float param value. Default is 1.23.') cmd2.set_defaults(func=second_command) args = parser.parse_args() args.func(args)It follows a usage example of the template above.$ python cli_template.py --no-root second-command --shared value --local-float 2.34I hope this turns out to be useful to you some day." }, { "title": "Manage Your Java Environment", "url": "/posts/manage-java-env/", "categories": "Software Engineering", "tags": "java", "date": "2018-08-19 00:00:00 +0200", "snippet": "In case you are familiar with Pyhon, I guess you also have heard of virtualenv. This is a tool to create isolatedPython environments, which lets you easily create or switch projects between Python 2 and Python 3.In Java, there are also different version out there. While version 7 or 8 are probably still most commonly used in production,even newer versions like 10 (current default of Ubuntu 18.04) or the preview of Java 11 (release expected in late September 2018)are available, too. Consequently, it can happen that you are working on several projects with different Java version requirements. The question is now: how can we switch between different installed JDKs?There are of course multiple possible answers. Two of them are the following…A) Setting the default Java versionIn case you have multiple Java versions installed, you can change the default version using the update-alternatives tool:$ sudo update-alternatives --config javaThere are 2 choices for the alternative java (providing /usr/bin/java). Selection Path Priority Status------------------------------------------------------------ 0 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1101 auto mode 1 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1101 manual mode* 2 /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java 1081 manual modePress ENTER to keep the current choice[*], or type selection number:As you can see, the command will list you all installed versions from which you can choose from.A more detailed explanation for how to install/uninstall/configure Java on Ubuntu 18.04 can be found in this Linuxize article.B) jEnvjEnv is a command line tool to help you forget how to set the JAVA_HOME environment variable.It currently supports Linux and Mac OS X.The installation is short and described on the jEnv website. After installations, you can easily add JDK installations using the jenv add /path/to/java/home command:Afterwards, you can either list the existing environments:$ jenv versions system oracle64-1.6.0.39* oracle64-1.7.0.11 (set by /Users/hikage/.jenv/version)Also, you can configure the used environments either globally, locally (per directory) within the shell instance:$ jenv global oracle64-1.6.0.39$ jenv local oracle64-1.6.0.39$ jenv shell oracle64-1.6.0.39Bonus tip: Maven Enforcer pluginIn case you manage your project with Maven in a team, I can highly recommend to use theEnforcer plugin. It provides goals to control certain environmentalconstraints such as Maven version, JDK version or OS family along with many more built-in rules and user created rules.As an example, we had the problem in our team that some integrations tests ran perfectly on our Jenkins, as well as on my colleague’s machines, but not on mine in case I was running mvn install. However, these tests did not fail when running them using IntelliJ. It simply turned out that my default JDKwas suddenly set to version 10, because I recently updated my machine from Ubuntu 17.10 to 18.04. I was completely unaware of this to that point of time.In case this sounds useful for you current project, then simply read theUsage page of the plugin’s project website." }, { "title": "Benchmarking TensorFlow Performance on eGPU", "url": "/posts/benchmark-tensorflow-egpu/", "categories": "Machine Learning", "tags": "benchmark, tensorflow, egpu, performance", "date": "2018-04-17 00:00:00 +0200", "snippet": "In the last post, I wrote about how to setup an eGPU on Ubuntu to get started with TensorFlow. I shortly mentioned that a eGPUis definitely worth it for Machine Learning, but I did not tell any numbers. This article tries to catch up on that. There are a gazillion benchmarks already out there about GPU gaming performance. A handful of them also include eGPU benchmarks,such as this example by egpu.io.One important thing that that these eGPU benchmarks show is that the use of an external display isfrom benefit, because otherwise the Thunderbolt 3 port becomes a bigger bottleneck. This is due to the fact that each rendered frame has be sent back to the internal display, which consumes valuable bandwidth ofthe 40 Gbps Thunderbolt 3 connection. However, there is no alternative for using an eGPU for Machine Learning, because the computed gradients have to be sent back to the CPU.Talking about Machine Learning, there are a few articles our official benchmarks about TensorFlow performance available, but either these are about desktop performance, or about multiple Tesla GPUs for business. With this post, I want to put a focus on the eGPU performance, how it compares to the pure CPU performance of the notebook. Furthermore, I added some more results to have a better comparability. In detail, I added the performance of my previousand still beloved ThinkPad X220 from 2011, as well as the CPU and GPU offers from FloydHub. Together with my new ThinkPad X1 Carbon 6th Generation notebook, I run these test configurations on 3 different data-sets and models, using the default settings provided by tensorflow/models,namely CIFAR10 and MNIST using a CNN, and PTB using an LSTM.Test setupThe used hardware specs of the benchmarks is as follows: X220 CPU: i5-2520M (2 cores), 8 GB RAM, 250 GB Samsung Evo 850 SSD Floyd CPU: Intel Xeon (2 cores), 8 GB RAM, 100 GB SSD Using free Beginner pricing Floyd GPU: Nvidia Tesla K80 12 GB VRAM, 61 GB RAM, 100 GB SSD The Tesla K80 is actually a dual-GPU with 24 GB VRAM total Using free Beginner pricing and 10h free GPU access X1 CPU: i7-8550U (4 cores), 16GB RAM, 512GB NVMe SSD X1 eGPU: Nvidia GTX 1070Ti 8GB VRAM, 16GB RAM, 512GB NVMe SSD Via Sonnet Breakaway Box 350W and Thunderbolt 3 with 40Gbps And the software setup is the following: Ubuntu 17.10 Nvidia driver 387.34 Python 3.6.3 TensorFlow r1.5 (pip package)BenchmarkLet’s get started with the first benchmarks. In each benchmark, I ran either the whole script with default settings,or the model for some minutes and took the average examples/seconds of the last 10 outputs to get a rough estimateof the performance.CIFAR-10This script can be found on GitHuband is described it detail on the TensorFlow website. It is a common benchmark in machine learning for image recognition. It uses a simple convolutional neural network architecturedescribed in this TensorFlow tutorial.We did not change any of the default values. Consequently, we used a batch size of 128, while each image has a size of 24x24 pixels.In contrast, the original CIFAR-10 benchmark uses 32x32 pixel images.Benchmarks using a CNN on the CIFAR-10 datasetWhile executing this model on the X1 eGPU, only about 601MB of the VRAM are occupied, while the GPU is utilized by about 85%. One thing that is to note for the X1 CPU setup it starts with up to 850 examples/sec for about 50 batches, which then quickly drops down to about 350 examples/sec on average. I guess this might be due to throttling of the CPU, which is a common “problem” in ULV CPUs, which are not built for continuous workload, especially in a super thin notebooklike the X1 Carbon. The Floyd CPU performance is underwhelming. Also the Floyd GPU performance of the Tesla GPU, which is less then half of the GTX 1070Ti used in X1 eGPU.MNISTThe script for this benchmark can be found on GitHuband the detailed description of the model on the TensorFlow website. This model uses a simple 2-layer CNN for image classification. To be honest, I actually wanted to use a fully-connected modelhere instead, but no standard model was provided by TensorFlow. Also, I did not want to come up with my own model, because I hope using standard models makes it easier to compare these number with results from others. Again, we did not change the default hyperparams. Consequently, we are using images of size 28x28 pixeland a batch-size of 64 for 10 epochs, with a validation of 5000 samples every 100 training steps.Benchmarks using a CNN on the MNIST datasetDuring training, the 465 MB VRAM of the eGPU was used, while it was utilized by about 81%. Since this benchmark is quite small,I timed the full training using the time python convolutional.py. Comparing my old X220 CPU which I still used abouta month ago with my new X1 eGPU setup, instead of waiting for half an hour, it does not even take a minute anymore.That’s a huge difference!PTBThis script can be found on GitHub and is based onthis whitepaper. It uses a 2-layer LSTM model with 200 hiden units on a challenging task oflanguage modeling. The default small config is used, which uses a batch-size of 20.Benchmarks using an LSTM on the PTB datasetThe relative performance is more or less similar to both benchmarks before. Honestly speaking, I actually thoughtthe performance speedup of a GPU on a recurrent model is lower compared to a CPU than on a convolutional model. But it looks like I was wrong.When you compare my results to the ones from thisMedium article,it looks like the Thunderbolt 3 bottleneck is almost negligible when the eGPU is used for machine learning." }, { "title": "How to Setup an eGPU on Ubuntu for TensorFlow", "url": "/posts/setup-egpu-ubuntu-tensorflow/", "categories": "Machine Learning", "tags": "tensorflow, egpu, performance, linux", "date": "2018-04-04 00:00:00 +0200", "snippet": "I remember when I read about eGPUs for the first time. The symbiosis of having a light weight laptop at university or on the go, but still having a desktop like power horse when having some spare-time at home sounded like a dream. But everything faded into obscurity because I almost lost full interest into gaming the last years.But this changed, since I’m spending a lot of time in deep learning since about two years. And it’s well known that takingadvantage of a GPU boosts training time by a huge margin. That’s why I tried to get access to a high-performancegraphics card in order to be able to train non-trivial networks and so some more serious research.At first, I had a look at some offers in the cloud. I did not try out a GPU-enabled instance on AWS, because the use a billing based on a hourly rate. This means that you have to pay for a full hour, even when you just run a simple example for 1 minute. Next, I checkout out the 300$ free credit on Google compute engine.Unfortunately, the offer was limited to a 8-core CPU instance, while no GPU instance was available. Last but not least,I checked out FloydHub, which actually worked quite well. The free version comes with 10 hours of GPU access on a Nvidia Tesla K80.However, this is a dual-GPU and you only get access to one of them, so the performance is actually worse than it looks likeon most benchmarks.After checking out some of these cloud platforms, I was still curious about how an eGPU performs with TensorFlow. There was basically no benchmark available regarding eGPU setups for Machine Learning. Most or even all of them are focused on pure gaming. And that’s why I thought: well, then do it yourself!Of course, there were two big bullet points which made me hesitate some more days: High GPU prices due to crypto-currency mining No official support and only very few resources for most eGPU systems on LinuxTL;DR Yes, it is worth it!InstallationWhile the setup of the eGPU on Windows is literally plug &amp; play, there is much more to do on Ubuntu 17.10.In this post, I wanted to share how I achieved to run a simple TensorFlow r1.6 example on the eGPU. The test-system in my case was the ThinkPad X1 Carbon 6th Gen.1. UEFI/BIOS security settingsOn my system, I had to disable some security features in the UEFI/BIOS settings. I had to disable the following,otherwise my eGPU was not detected: Secure Boot Thunderbolt Security Level2. Install NVIDIA graphics driverNext, the graphics drivers have to be installed. These available driver versions for linux can be found onlaunchpad. Interestingly, I installed thelatest version 390 first, but after installing CUDA, the version 387.34 has been installed out of the sudden. I’m not sure whether CUDA is bundled with an appropriate graphics driver, but at least the version number changedafter the installation. Nevertheless, I performed the following commands.Optionally, uninstall old drivers first:$ sudo apt-get purge nvidia*Then get and install the drivers:$ sudo add-apt-repository ppa:graphics-drivers$ sudo apt-get update$ sudo apt-get install nvidia-390Replace the 390 with the version you would like to install. To verify the driver installation, you can use the following command:$ lsmod | grep nvidiaThe output should be non-empty in case of success. A restart after the driver installation might be required.To be able to use the nvidia-smi command, I added the following lines to my ~/.bashrc script:# NVIDIA driver and toolsexport PATH=\"$PATH:/usr/lib/nvidia-390:/usr/lib/nvidia-390/bin\"export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/lib/nvidia-390:/usr/local/lib\"Again, replace the version number with the version you installed previously.The NVIDIA system management interface might still fail with an error. This is because you have to manually switch toyour dedicated GPU first. This can be done using the following command:$ sudo prime-select nvidiaAs far as I know, this is kind of the Linux counterpart to NVIDIA Optimuson Windows. Enter the nvidia-smi command again, and you should get the anticipated output.$ nvidia-smiTue Apr 4 23:33:18 2018 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387.34 Driver Version: 387.34 | |-------------------------------+----------------------+----------------------+| GPU Name Persistence-M| Bus Id Disp.A | Volatile Uncorr. ECC || Fan Temp Perf Pwr:Usage/Cap| Memory Usage | GPU Util. Compute M. ||===============================+======================+======================|| 0 GeForce GTX 107... Off | 00000000:3E:00.0 Off | N/A || 0% 26C P0 35W / 180W | 0MiB / 8114MiB | 4% Default |+-----------------------------------------------------------------------------++-----------------------------------------------------------------------------+| Processes: GPU Memory || GPU PID Process name Usage ||=============================================================================|| No running processes found |+-----------------------------------------------------------------------------+ Please remember that the prime-select command has to be executed every time you reboot your systemand reconnect your eGPU via Thunderbolt 3.3. Setup TensorFlow with GPU supportThe installation requirements for TensorFlow with GPU support can be found on the TensorFlow website. However, I found the installation is still a bit tricky, especially because it is important to install the exact CUDAand cuDNN versions. That’s why I want to share the commands and links I have used nevertheless. In my case,I installed TensorFlow r1.6 via pip, which requires CUDA 9.0 and cuDNN 7.0. In my first try, I installed CUDA 9.1 and cuDNN 7.1,and it did not work. Importing TensorFlow in Python resulted therefore with a warning that the appropriate librariescould not be found.3.1 Download and install CUDA 9.0CUDA version 9.0 can be found on the Nvidia Developer website, while the latest version is available in the CUDA downloads.I installed the main binary first, then followed by both batches. To install the binary, I used the following commands:$ sudo dpkg -i cuda-repo-ubuntu1704-9-0-local_9.0.176-1_amd64.deb$ sudo apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub$ sudo apt-get update$ sudo apt-get install cudaFurthermore, add something like this e.g. to your ~/.bashrc script:# NVIDIA CUDAexport PATH=\"$PATH:/usr/local/cuda/bin\"export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64\"3.2 Download and install cuDNN 7.0Navigate to the cuDNN page, register, and download the appropriate cuDNN version.In my case, I installed version 7.0.5, which was the latest version of the 7.0 release. Afterwards,you should set the CUDA_HOME environment variable, such as in your .bashrc script:# NVIDIA cuDNNexport CUDA_HOME=\"/usr/local/cuda\"3.3 Install GPU-enabled TensorFlowI usually recommend to use a virtual environment for every project:$ sudo apt-get install python3-pip python3-dev python-virtualenv$ virtualenv -p python3 gpu-env$ source gpu-env/bin/activate(gpu-env) $ pip install tensorflow-gpu==1.6(gpu-env) $ python&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; sess = tf.InteractiveSession()2018-04-04 01:11:50.496859: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA2018-04-04 01:11:51.911926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2018-04-04 01:11:51.912711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683pciBusID: 0000:3e:00.0totalMemory: 7.92GiB freeMemory: 7.81GiB2018-04-04 01:11:51.912725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 02018-04-04 01:11:52.376920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7543 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:3e:00.0, compute capability: 6.1)&gt;&gt;&gt;Hell yeah, we are finally ready to rumble!" }, { "title": "Find your model's optimal hyperparameters with Hyperopt", "url": "/posts/find-model-hyperparams-with-hyperopt/", "categories": "Machine Learning", "tags": "hyperopt", "date": "2017-12-25 00:00:00 +0100", "snippet": "While checking out some tools for automated hyperparameter optimization, I came across a quite popular library calledHyperopt. It provides an implementation for Random Search andTree-of-Parzen-Estimators (TPE). Unfortunately, most examples out there us a dummy function to replace the model,but I could not find any example that uses TensorFlow. That’s why I wanted to provide a basic simple Hyperopt examplewith TensorFlow. This example can be found on my GitHub’smachine-learning-examples repository.Do you have any experiences with other libraries for hyperparameter optimization? I would be happy if you share your experiences?If so, I would appreciate reaching out to me. For instance, I have read that a Sacred extensioncalled Labwatch also allows to define a search space for algorithmic hyperparameteroptimization, but comes with different algorithms." }, { "title": "Better IDE Support for Python with Type Hints", "url": "/posts/python-type-hints/", "categories": "Software Engineering", "tags": "python, typing", "date": "2017-12-23 00:00:00 +0100", "snippet": "About 12 years ago, I started to learn programming with Java and C#. Both languages are type-safe and have therefore a greatsupport when using an IDE like Eclipse, IntelliJ or Visual Studio. But throughout my software development journey,I also made my hands dirty with other dynamically typed languages like JavaScript or Python.While checking out Angular2 more than a year ago, I used TypeScript for my first time,because it was recommended by the Angular team. I quickly realized how much painless it was to develop a web applicationwith TypeScript instead of using classic JavaScript. The ability to strictly assigning a data type to a variable allowsany IDE to offer much better tooling support, such as IntelliSense. At least in my point of view, programming in TypeScriptfelt much more like programming in C# than in JavaScript, where I always felt like I had to know every possible function nameby heart. Which was especially difficult when you use JavaScript on a very non-regular basis.Since I changed my focus from mobile software development more and more to machine learning, Python is now becoming more and moremy daily bread and butter. Unfortunately, I felt like facing the same dilemma. Again, Python is a dynamically typed languageand the tooling support sometimes feels horrible, even when using a great IDE like PyCharm. As an example,check out the following function:def print_array(var, data): print('Variable {} shape: {}'.format(var, data.shape))This function signature is hard to read. What is var and which type does it have? Is data a list, tuple or a numpy array?Usually, we would have to read the docs or even read the underlying code to get a better idea about this function.But doing so takes a lot of time.But there is a solution! Thanks to PEP 484, it is possible to assign a typeto a functions parameter or return value:import numpy as npdef print_array(var: str, data: np.ndarray) -&gt; None: print('Variable {} shape: {}'.format(var, data.shape))print_array('array', np.ones((4, 2)))Take a look at the signature of the print_array(...) function. Now it is much more clear how to use this function.And also an IDE is now able to provide better tooling support. In case the function requires a data structure such as list,tuple or dictionary as its parameters, the typing module enables to solve this:from typing import Listdef median(data: List[int]) -&gt; float: length = len(data) sdata = sorted(data) if length % 2 == 0: return (sdata[(length - 1) // 2] + sdata[length // 2]) / 2 else: return sdata[length // 2]print(median([3, 5, 2, 1, 4,6]))Needless to say, these type hints can be used in case of object orientation as well. Take a look at the following snippet:from typing import Tupleclass Person(object): def __init__(self, name: str, age: int): self.name = name self.age = age def info(self) -&gt; str: return ': {}, {}'.format(self.name, self.age)def create_person() -&gt; Tuple[int, Person]: id = 42 p = Person('Alice', 32) return id, pid, person = create_person()print(person.info())To sum up, type hints help to understand and use functions in Python. Furthermore, the use of type hints improve the toolingsupport of your IDE. As an example, PyCharm warns you in case you call a function witha wrong parameter type:Type warning in PyCharmMoreover, there are many situations where PyCharm is suddenly able to tell you which functions any variable is able to callor which properties are offered by an object:Python typing IDE support in PyCharmAfter playing around with these type hints, I cannot imagine anymore how I could survive without them.At least as a fan of strictly typed languages, this Python feature is priceless." }, { "title": "Why should I install TensorFlow from Source?", "url": "/posts/why-tensorflow-from-source/", "categories": "Machine Learning", "tags": "tensorflow, performance", "date": "2017-05-29 00:00:00 +0200", "snippet": "There are various ways to install TensorFlow. For instance, you can install it using a Docker imageor Python’s package manager pip. But since the version 1.0 release of TensorFlow, you probably might have faced the followingwarnings each time you run a TensorFlow session:2017-05-29 11:50:22.977500: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.2017-05-29 11:50:22.977513: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.2017-05-29 11:50:22.977517: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.2017-05-29 11:50:22.977519: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.2017-05-29 11:50:22.977521: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.Of course, these are just warnings you could simply ignore, or even deactivate using the following shell command:$ export TF_CPP_MIN_LOG_LEVEL=2But this just hiding and not actually solving the problem. What are these warnings about? At least the TensorFlow pip packagesr1.0, r1.1 and r1.2 are compiled with no support for latest instruction sets (SSE 4.1, SSE 4.2, AVX, AVX2, FMA) of newer CPUs,such as Skylake or Kaby Lake. The reason might be that users of older CPUs are able to install and use these packages withoutany problems as well. But in order to take advantage of these newer instruction sets, it is currently required to installTensorFlow from source.InstallationThe installation process is actually simple to follow and described on the TensorFlow webpage. To install the (currently) latestrelease 1.2 from Source, check out thisInstall TensorFlow from Sources guide.I’m not completely sure, but I think that prior r1.2, it was requried to activate these instructions one by one:$ sudo bazel build --config opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-mavx2 \\ --copt=-mfma //tensorflow/tools/pip_package:build_pip_packageBut in r1.2, these copt options have been renamed. For example, -mfma has been renamed to -mnofma. Consequently, it looks likethat these instructions are now enabled by default when we install TensorFlow from source. Hence, we can simple use the defaultconfiguration and simply combile it using Bazel without any additional options:$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package The command above is about the CPU only setup. The GPU enabled setup is different.This took almost 39 minutes on my Lenovo T470 (7200U, 16GB RAM, 512GB NVMe SSD) machine, so grab a coffee!And don’t worry regarding all these compiler warnings. You will definitely see lots of them.After the compilation, you can create and install the pip package:$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg$ sudo pip install /tmp/tensorflow_pkg/tensorflow-1.2.0rc1-cp27-cp27mu-linux_x86_64.whlPlease keep in mind that the file name of the used /tmp/tensorflow_pkg/tensorflow-1.2.0rc1-cp27-cp27mu-linux_x86_64.whlfile could be different depending of the configuration you have chosen. So simply check out the generated file in the/tmp/tensorflow_pkg folder.The verdictIn case you are using the CPU only version, it is definitely worth to compile it from source. I checked it out on a simpleexample and the performance feels to be about 1.5 to 2 times better. But depending on the problem, you might even see a speed upof factor 4 to 8. Especially large matrix multiplications, like in fully-connected layers with a lot of neurons, can benefit a lot from these newer instructions. Now, you might think that you do not need to compile from source in case you areusing the GPU enabled version of TensorFlow. But I would recommend to compile from source nevertheless. The reason is that in case you are using a input pipeline with a lot of preprocessing, you will definitely see a performancedifference as well. At least it is recommended to assign all ops to the CPU that are related to the input pipeline, using the with tf.device('/cpu:0') statement." }, { "title": "Python + Matplotlib = Must Have on Your System", "url": "/posts/python-matlab-must-have/", "categories": "Data Visualization", "tags": "python, matplotlib, data, visualization", "date": "2017-04-01 00:00:00 +0200", "snippet": "In the last few weeks, I had to visualize some data from time to time. And for me, it turned out that the Python libraryMatplotlib is one of the best tools to do some quick plots. I cannot imagine that I have neverinstalled Python on the Windows partition of my laptop, but only on my Linux partition. And I can really recommend to havePython and Matplotlib installed on every device, so that you have these tools at hand whenever you need to visualize some data.In this short post, I would like to write down the few simple steps you should do.Getting startedIf not available already, please install Python. There are many ways to do it, such as from theofficial Python Software Foundation, or via your package manager on Ubuntu:$ sudo apt-get update$ sudo apt-get install pythonNext, install Matplotlib using pip package manager:$ pip install matplotlibThen run a Python terminal, import matplotlib.pyplot and make plot with just a few lines of code:import matplotlib.pyplot as pltplt.plot([8,4,2,1,0,1,2,4,8])plt.show()You will then see the results in an interactive window:Example plot with MatplotlibYou can also perform multiple plt.plot() calls before showing the graphics, in order to stack multiple lines in asingle diagram. And of course, the library allows you to do much more. To get started, check out thistutorial." }, { "title": "Deep Learning Meetup 2017 Q1 in Munich", "url": "/posts/deep-learning-meetup-munich/", "categories": "Events, Machine Learning", "tags": "nvidia, meetup, deep learning", "date": "2017-02-09 00:00:00 +0100", "snippet": "I could check out another deep learning meetup. This time it was hosted at Google’s Isar Valley here in Munich.The three interesting walks were about the following topics: Visual Sentiment Analysis with Deep Convolutional Neural Networks (by Dr. Damien Borth, DFKI) Strategies for AI Deployment (by Henrik Klagges, TNG Consulting GmbH) DGX-1 and SATURNV: The World’s Most Efficient Supercomputer for AI and DL (by Ralph Hinsche, Nvidia)In the third talk of Nvidia, we were also able to hold a test sample of the latest Tesla P100 in our hands,which is one of the building blocks of Nvidia’s deep learning super computers calledDGX-1. This is a nice super toy that every AI-researcher would liketo have under the Christmas tree. Unfortunately, a single device costs more than 100.000 USD.Holding a Nvidia DGX-1 in my hands" }, { "title": "Intel AI Days 2017 in Munich", "url": "/posts/intel-ai-days-munich/", "categories": "Events, Machine Learning", "tags": "intel, conference, deep learning", "date": "2017-02-02 00:00:00 +0100", "snippet": "I had the pleasure to check out Intel’s first AI days in Europe. At ICM in Munich, Intel presented their latest advancementsin Artificial Intelligence and Deep Learning in both hardware and software. As one of the biggest player in thehardware industry, they talked a lot about the next wave Xeon CPUs calledLake Crest, that is optimized for Deep Learning.Furthermore, a representative of Nervana Systems introduced their deep learning platform,which has been acquired by Intel for more than 400 Mio. USD in October 2016.Intel AI Days 2017 Kick-offAdditionally, they talked a lot about low-level optimizations that they have done in order to accelerate many deep learningusing Intel hardware, such as (Intel Math Kernel Library (MKL)). In some examples,they shows amazing improvements by a factor of up to 400. This sounds to good to be true in my ears, but even half of thatis more than welcome! They presented their Neon framework,which feels to be in between TensorFlow and Keras, as well as a high-level and simple to useIntel Deep Learning SDK for non-programmers. The latter one is currently only suitablefor image data. Along with this presentations, me and some others in the audience felt a little bit confused why Intel presentsseveral deep learnings frameworks, and why not just focuses on a single one.Intel Deep Learning SDKOne last thing that kept in my mind after both days: bar charts, bar charts and even more bar charts.Intel kind of really loves bar charts. I couldn’t stand them any longer after a while, especially because of their redundancyfrom one presentation to the next. Nevertheless, I’m excited if consumer market CPUs will also benefit from these advancementsin the near future.All presentation slides can be found on Inteldevconference." }, { "title": "UWPCore - A Development Acceleration Framework for the Universal Windows Platform", "url": "/posts/uwpcore-dev-accelerator-framework/", "categories": "Projects, Windows", "tags": "windows phone, uwp, framework, csharp", "date": "2017-01-24 00:00:00 +0100", "snippet": "Since it has proven stability and reliability in two successful Windows 10 project for more than a year, we thought about to open source our service-driven framework. Even when it has not reached version 1.0 yet,you can nevertheless use it for your next project right now.Check out the UWPCore Framework on Github. I developed this framework in course of the last year together with my friend Patrick Mutter.UWPCore Framework logoMore information about the framework is written down on the landing page of the repository. It even includes a short description of how to get started. In case you use our framework, and consider any kind of problem or bug, feel free to either open an issue on Github,or via a pull request." }, { "title": "TensorLight - A High-Level Framework for TensorFlow Projects", "url": "/posts/tensorlight-framework/", "categories": "Projects, Machine Learning", "tags": "tensorflow, python, deep learning, framework", "date": "2016-11-08 00:00:00 +0100", "snippet": "In the course of the development of my Master’s Thesis “Deep Learning Approaches to Predict Future Frames in Videos” at TUM,I realized that the high flexibility of TensorFlow has its price: boilerpate code.Many things that are needed in almost every neural network training or evaluation script have to be implementedover and over again. To that end, I started to implement a high-level API for Google’s machine intelligence library,called TensorLight.TensorLight Framework logoTensorLight comes with four guiding principles: Simplicity: Straight-forward to use for anybody who has already worked with TensorFlow. Especially,no further learning is required regarding how to define a model’s graph definition. Compactness: Reduce boilerplate code, while keeping the transparency and flexibility of TensorFlow. Standardization: Provide a standard way in respect to the implementation of models and datasets in order to save time.Further, it automates the whole training and validation process, but also provides hooks to maintain customizability. Superiority: Enable advanced features that are not included in the TensorFlow API, as well as retain its full functionality.The project solution of my thesis is almost entirely based on this framework. I was able to refactor and the majority of mytraining and evaluation code, as well as all the best practices I gained throughout this phase into it." }, { "title": "Master's Thesis - Deep Learning Approaches to Predict Future Frames in Videos", "url": "/posts/master-thesis-deep-learning-frame-prediction/", "categories": "Machine Learning", "tags": "tensorflow, python, deep learning, computer vision, research, lstm, education", "date": "2016-10-17 00:00:00 +0200", "snippet": "I finally finished my Master’s Thesis in the Computer Vision chair at TUM.In the course of this thesis, I analyzed existing deep learning approaches to predict future frames in videos.Based on these findings and other modern deep learning practices, such as batch normalization, scheduled sampling to improverecurrent network training or ConvLSTMs, we were able to reach or event outperform state-of-the-art performance infuture frame generation.So far, many people asked me about the practical application of frame prediction. Unfortunately, it won’t tell us the end of anycliff-hanger movie such as Inception, but the main purpose of such a system is not to generate a perfect forecast of thelong-term continuation of any movie clip. This completely impossible in my opinion, since there is not always a wrong or rightin many situations. A neural network cannot be able to predict every decision made by all objects inside the scene.Furthermore, the pose of the camera or the environment could change unexpectedly. More interestingly, the trained model hasto be able to distinguish foreground and background, as well as encode the content and dynamics of the frame sequence.In this thesis, we use this learned representations to predict the possible future frame sequence,using a completely unsupervised learning process. Parts of this trained neural network could be reused in anysupervised learning task, such as action recognition in videos. Also, a similar model architecture could be used to traina neural network that is able to generate high speed videos using frame interpolation, or in context of video compression.But let’s get back to the application example that was used within the thesis: future frame prediction in videos.To assess the model, we used three different datasets with increasing complexity. First, we usedMovingMNIST using two digits (top).Surprisingly, the model also delivered good results when we performed an out-of-domain test using one or three digits (bottom).The ground truth animation on the left is shown in comparison to the multi-step frame prediction to the right.MovingMNIST predicted on proposed Conv2D LSTM model using three digitsMovingMNIST predicted on proposed Conv2D LSTM model using three digitsIn a second experiment, we used video game recording of MsPacman.As it can be seen in the prediction example below, our trained 2-layer ConvLSTM Encoder-Predictor model is able to captureseveral dynamics of the game, such as the movement of Pacman and the ghosts, the blinking of the big dot in the top-right corner,as well as es fact that Pacman is eating the dots within the maze.MsPacman predicted on proposed Conv2D LSTM modelIn our last experiment, we trained our model on the UCF-101 training set.This is a much harder problem, since the environment comes with unlimited possibilities, the camera could exhibitsmovement and rotation, and so on. Like many other solutions, we can notice a blur-effect in the generated future frames,even that we take advantage of perceptual motivated loss terms, such as SSIM or GDL. However, some results look satisfactorynonetheless. As an example, the zooming of the camera is captured and correctly continued in the soccer example below.UCF-101 predicted on proposed Conv2D LSTM modelOf course, there is much more to tell. But the main intention of this post is to provide a rough idea about what has been done,as well to show some prediction examples of my trained recurrent decoder-encoder network.In case would like to know more about it, just have a look at my written Master’s Thesis or write a comment to this post." }, { "title": "Action Note Video Reviews", "url": "/posts/action-note-video-reviews/", "categories": "Projects, Windows", "tags": "windows phone, uwp, review, action note", "date": "2016-04-09 00:00:00 +0200", "snippet": "I realized there are at least two video reviews ofAction Note out there already.Of couse, I don’t want to withhold them from you.The first video was already released about 3 months ago. Consequently, they have been tested one of the veryearly versions of Action Note. Unfortunately, I have to admit the app was not fully stable at that point in time.However, I still like the video and the comments and feedback the reviewer shared about it.Action Note video review on Lifestyles DefinedThe second video was just released about a month ago. In contrast to the previous video, it shows it the latest version.The title of the video is Best Apps for Windows Phone 8.1 Windows 10 Mobile February 2016. There are several apps presentedin the video. The review for Action Note starts at 3:15.Action Note video review on Best Apps for Windows 10 Mobile February 2016Besides these videos, Action Note has also been reviewed already by quite a few renowned Windows related websites such as WindowsCentral orWindows Area." }, { "title": "Bug in ComboBox of UWP Apps when using Custom Styles", "url": "/posts/combobox-uwp-custom-styles-bug/", "categories": "Software Engineering", "tags": "windows phone, uwp, csharp, bug", "date": "2016-02-25 00:00:00 +0100", "snippet": "I’m investigating a weird issue for some of my app users since a while already, which I’m not able to reproduce on my PC,Surface tablet or Lumia phones. However, in the reviews of my Action Noteapp, I can read that some users seem to have troubles to open the settings page. First, I thought these are wrong reports.But after reading it a couple of times from different users made me thinking. And at least after I received the first bugreport via Email, I realized this requires a closer look. After some detailed analysis I could figure out that these crashesmust be related to the &lt;ComboBox /&gt; control. But I could not find anything useful that could help to resolve this problem.After even more problem analysis, debugging and testing, I could finally narrow down that the root cause of the problem:Custom Styles used in context of a ComboBox. It even does not matter how this style is defined. Even using the generateddefault style from Microsoft Blend ends up with the same effect. Consequently,there seem to be only two options left:a. Use a ComboBox without any Custom Style Use a completely different controlFurthermore, I could figure out the following: The problem does not seem to appear on Windows 10 Mobile devices Only a few users on Windows 10 PC are affected It seems only PC users are affected that installed Windows 10 via update, instead of doing a clean installationConsequently, the use of &lt;ComboBox /&gt; in a Windows 10 UWP app requires attantion at the moment, as it can very unexpectedlycause instability. More details and progress of resolving this issue can be followed in mythread in MSDN.Edit:It looks like I was indeed looking into some sort of nasty bug deep down in the Universal Windows Platform: @Benjamin Sautermeister, It’s really nice that you post the research result to here. I’ve purposed your answer since I think it will also be good for other customers who meet the same problem. Best regards,Barry" }, { "title": "powernAPP App Reviews Supports UZH Research Project", "url": "/posts/powernapp-reviews-ardoc/", "categories": "Software Engineering, Research", "tags": "windows phone, uwp, csharp, bug", "date": "2015-12-30 00:00:00 +0100", "snippet": "ARdoc is a tool developed by students ofUniversity of Zurich for automated analysis of app store reviews. A Java tool to automatically recognize natural language fragments in user reviews that are relevant for developersto evolve their applications.It processes and classifies reviews in natural language and generated aggregated summaries. These contain for examplepotential feature requests, reported issues or frequently asked questions. The latter could for example indicatethat your app might not be fully intuitive to users.It is to mention that my app powernAPPplayed an supporting role in the published whitepaper with the title ARdoc: App Reviews Development Oriented Classifier(PDF). The many reviews of powernAPP served as test data for theproposed ARdoc system. If you take a closer look at the published video,then you might notice that the shown reviews are from my app. Last but not least, they mentioned me in the acknowledgment sectionof the paper. Acknowledgments We thank Benjamin Sautermeister and André Meyer forhelping us to evaluate the accuracy of ARdoc validatingthe results of the automatic classification on user reviews oftheir mobile apps. Sebastiano Panichella gratefully acknowledges the Swiss National Science foundation’s support forthe project “Essentials” (SNF Project No. 200020−153129).Personally, I think such a tool could be very helpful for (indie) app developers like me. In the meantime, I have 22 appsin the Windows Store. In total, I receive around 10 to 100 Reviews each single day. Therefore, without any sort of automation,it is almost impossible to read and respect each of them individually." }, { "title": "9 Reasons Why Microsoft Should Revise the Action Center", "url": "/posts/reasons-microsoft-should-revise-action-center/", "categories": "Feedback, Windows", "tags": "windows, windows phone, uwp, action center", "date": "2015-12-13 00:00:00 +0100", "snippet": "One of the best new features of Windows 10 is the introduction of the Action Center. It centralizes the most importantinformation of any app in just one place, is easy to access and also provides shortcuts to important settings.In consequence, a feature in such a central position should be very well tested, right? Unfortunately, after spending a lot of time working with the Action Center,especially with the API during the development of Action Note, it turns out to be kind of premature.That’s why I wanted to collect all these issues, UI glitches and bugs in a list.Hopefully this is contributing to improve the Action Center in the (hopefully) near future. So, here we go…1. Input field of an adaptive tile can lead to a graphical glitchAffected platforms: Windows 10Description: The new adaptive tiles of Windows 10 are really awesome. But whenever a text input field is used,the Action Center’s UI changes the font’s foreground color for whatever reason.Multi-line input in Action Center with unexpectedly inverted font color2. The input field’s cursor of an adaptive tile is obviously misplacedAffected platforms: Windows 10Description: It’s a small thing, but very obvious and just ugly. The cursor of an input field is misplacedand shifted to the top left. I’m not sure why it has not been fixed since the release of Windows 10,because it is so obvious.Misplaced cursor in Action Center3. An expanded toast sometimes collapses unexpectedlyAffected platforms: Windows 10Description: When you expand a toast notification to access the hidden content, either just the full textor even buttons or text input fields in case of an advanced adaptive toast, the toast sometimes collapsesimmediately after expanding it or trying to click on a button or setting the focus on the text input field.That tiny bug harms the usability a lot.4. Input field’s placeholder text of an adaptive tile does not support line wrapping on every platformAffected platforms: Windows 10 MobileDescription: I am not sure if it’s a bug on Windows 10 Mobile or on the PC Version. But in my point of view,all platforms should behave the same at least. While Windows 10 for PC/Tablet supports line wrapping forthe placeholder text (by using \\r), this is not possible on Windows 10 Mobile.Multi-line placeholder in Action Center5. Input field’s line wrap of an adaptive tile differs on both platformsAffected platforms: Both Windows 10 and MobileDescription: Again, this is a very minor issue, but I think all platforms should behave the same.When a user enters a text that contains an ENTER to perform a line wrap, on Windows 10 Mobile \\r is used,while Windows 10 uses \\r\\n.6. The toast history change type in a background task is always “Removed” and never “Cleared”, even when the user clears all notesAffected platforms: Both Windows 10 and MobileDescription: An app can register a background task to detect user manipulations on its toast messages in the Action Center.And the ToastHistoryChangedType (see docs)should tell us which kind of change it was. But currently it looks like it is not possible to distinguish whether the user justremoved a single toast message or all of them. Either by using the “Clear all” button or my swiping the title to the right.Status: Microsoft already commented on that in my MSDN thread.They confirmed the issue and are going to fix it.Clearing all notes in Action Center7. The removal of a toast notification does not tell the background task which toast ID was removedAffected platforms: Both Windows 10 and MobileDescription: This is clearly not bug, but I think a missing functionality of the API.When you app is launched by a toast notification or a live tile, the API provides methods to identifythe notifications by which the app was launched. But when you want to detect which notification was removedin a background task, there is no supported method provided by ToastNotificationHistoryChangedTriggerDetail(see docs).Currently you have to do an unnecessary workaround and save a list of all notification that have been pushed by the application,as well as perform a diff with the currently shown notifications. A lot of horrible clutter code…8. When a new toast notification is pushed using the property SuppressPopup = true, following changes to toast in the Action Center can have an unexpected behaviorAffected platforms: Both Windows 10 and MobileDescription: When replacing a toast using tag/group, if you use SuppressPopup (see docs) on the new toast,the toast will fail to be updated until you reboot the computer. And if you pop a subsequent toast without SuppressPopup,it will appear as a new toast due to the previous broken SuppressPopup toast.Status: Microsoft already commented on that in my MSDN thread.They confirmed the issue and are going to fix it. They also proposed a workaround, which could be sufficient for you.9. Toast notifications cannot be mutedAffected platforms: Windows 10 MobileDescription: There are several ways to make a toast notification silent when it is pushed to the Action Center.First, the developer can set silent=true in the &lt;audio&gt; tag of the adaptive toast. As an alternative,the developer could set “src=no_sound.wav”, so just reference an empty audio file. Secondly, the user is also ablethe set or mute the sound of a toast notification for each app in the setting. Unfortunately, this is not properly working.Because when the user has opened the Action Center on his mobile device, the default sound is played nevertheless.This is pretty annoying in case of my latest app Action Note,especially in combination with issue number 8 above and the suggested workaround of Microsoft. Think about the following scenario:Our app shows 5 Notifications and we want to update the bottom one. Because we currently cannot just update it,we have to recreate all notifications. When the user just having a look at the Action Center,it follows that the sound is played 5 times in a row. My app Action Note currently has to recreate all notificationsevery time the user creates a new note. And creating a note in the Action Center means that the Action Centeris always visible to the user. You can image the consequence when the user has about 10 notes in his list.Sounds like a Jackpot in Las Vegas. Pretty annoying, right?Have you found even more issues of the Action Center? Awesome! Wait … that was probably the wrong word. I’m quite sure I forgot something. Just in case you know even more, please write them down in the comments section. Thanks!" }, { "title": "Daily Focus App Reaches ROYAL Status in AdDuplex HERO APPS", "url": "/posts/daily-focus-ad-duplex-hero-apps/", "categories": "Projects, Windows", "tags": "windows, windows phone, uwp", "date": "2015-12-07 00:00:00 +0100", "snippet": "You might have heard of the HERO APPS programm by AdDuplex. One a month,a few apps are distinguished by the AdDuplex network in different categories. While there are also different levels.A few days ago, my first Windows 10 app Daily Focusreceived the ROYAL badge, which is the second highest level.Not bad I would say, because this app was actually just meant for practice.ROYAL AdDuplex HERO APPS badge" }, { "title": "1 Millionen Downloads in Windows App Store", "url": "/posts/one-million-downloads-windows-store/", "categories": "Projects, Analytics", "tags": "windows, windows phone, downloads", "date": "2015-05-27 00:00:00 +0200", "snippet": "Last weekend, my apps overall downloads in the Windows Phone store reached the milestone of one million.Honestly speaking, I would never had dreamed of coming even close…Thank you for 1 million downloadsThis number is composed out of the overal sum of my 20 apps in the Windows Phone store.I did not include the downloads from the Windows 8 store. But these numbers are negligible anyways.Monthly (black) and accumulative (blue) downloadsWorth mentioning is the fact that my top seven apps contribute 90% of the overall downloads.The key drivers here are SpaceScribble,powernAPPand my latest app Photo Marker." }, { "title": "Internation Student Project in Texas", "url": "/posts/international-project-in-texas/", "categories": "University, Abroad", "tags": "university, android, project", "date": "2015-04-27 00:00:00 +0200", "snippet": "I was lucky enough this year to get accepted to participate in the international project of the Android programmingpracticle course of Technical University of Munich in partnership with Texas A&amp;M University in College Station.Road to HoustonFurthermore, as this project was about developing a showcase of a space robot powered by NASA certified hardwaredeveloped by the US team, which however can be controlled using an Android application developed by our German team,we also had the please to get invited to the NASA Johnson Space Center.Space Shuttle at Houston Space CenterLower stages of a Saturn V rocketAfter we completed our project work, we had a few days of spare time left to do a short road tip to Dallas, Fort Worthand Austin. Especially the Hamilton Pool Preserve has beenan amazing place to see.Hamilton Pool before we headed further to AustinBut I want to keep myself short here, because a colleague who joined that trip as well wrote a very extensive post named8500 Miles by Plane, 1500 Miles by Car – University Trip to the USabout our time in Texas already. Please enjoy reading it!" }, { "title": "German Windows Phone Store Highlihgts 3 of My Apps", "url": "/posts/thee-app-highlights-in-german-wp-store/", "categories": "Projects, Analytics", "tags": "windows, windows phone, downloads", "date": "2015-01-15 00:00:00 +0100", "snippet": "The Windows Phone store hightlights 20 apps in the app store every day.These highlights are different depending on the region, and are strongly influenced by the number of downloads.In the last few weeks, my apps appear recently at least in the German Windows Phone store.This has a significant positive impact in the download numbers for each of them.Windows Phone Store App HighlightsYesterday, I noticed by coincidence that probably for the very first time, three out of these twenty apps are from me.And I think this is something to be proud of, as I put a lot of time and effort into these apps that I develop in mypersonal free time.Furthermore, the German store is one of the most important in my case. Not because of the language, as a few of my apps aretranslated in more than ten languages already. But because users from the German region generate 49.2% of the overallin-app purchases, while on the other hand side only 7.3% of the total app downloads.Let’s see for how long my apps are here to stay in the top listings of the Windows Store.With downloads in range of 2,500 to 4,000 each day, I’m definitely more than happy at the moment." }, { "title": "500k Downloads in Windows Phone Store", "url": "/posts/500k-downloads-windows-store/", "categories": "Projects, Analytics", "tags": "windows, windows phone, downloads", "date": "2014-09-02 00:00:00 +0200", "snippet": "This weekend, the overall downloads of my apps and games in the Windows Phone store reached the milestone of half a million.500k downloads in Dev Center appIn case you are interested in more details, the following table shows a few more stats: App / Game Downloads Days in Store Downloads per Day AstropiXX 92,190 936 98.49 Developer’s Diary 79 386 0.20 Frequenzer 3,487 33 105.67 Photo-Info 9,041 138 65.51 pocketBRAIN 12,861 200 64.31 powernAPP 12,861 278 217.23 ScribbleHunter 15,960 534 29.89 ScribbleHunter Pro 1,665 534 3.12 seeMENSA 964 1299 0.74 SpacepiXX 48,379 1263 38.30 SpaceScribble 224,882 809 277.96 URI Launcher 1,009 141 7.16 VaderpiXX 5,042 897 5.62 voiceTIMER 898 271 3.31 Whip 26,988 185 145.88 Total 503,836   1063.39 I’m excited to see to reach the one million downloads milestone at some point. Assuming the downloads stay as is,then this should happen around Q2 in 2016." }, { "title": "WPI IMGD3000 Technical Game Development Course Inspired by My UnitTest Manager", "url": "/posts/wpi-imdg3000-tech-game-dev-testing/", "categories": "University, Abroad", "tags": "university, cpp, project, game dev", "date": "2014-08-13 00:00:00 +0200", "snippet": "Today, I received the following email from my Technical Game Development professor at Worcester Polytechnic Institute (WPI)in the US out of a sudden: Hi, Benjamin. Just a quick note to tell you I’ve created a Unit TestManager based on the one you started for the IMGD 3000 class lastyear. I’m looking to encourage students to do basic unit testing asthey do developments, and the framework you started is nice in itssimplicity. I’ve put up a sample athttp://dragonfly.wpi.edu/games/index.html and credited you with theearly version. Nice work. Anyway, thought I’d let you know.By the activity on your Web page (http://bsautermeister.de/) yourpersonal code development projects are coming along nicely! I’vejust switched to a Windows phone (a Nokia 1020) so tried outa few of your apps. Fun! Keep up the good work. Hope you are doing well. sincerely,MarkBackground of this email is the following. In a course I visited at WPI, we learned about the fundamentals of developinga game engine from scratch. I a larger project in scope of 3 months, each student developed a full blown ASCII basedgame engine in C++. And with this engine, each smaller team of two then had to develop and present a game.You can check out videos and results of that course on the official IMGD 3000website. Our game called Planetary Defense is also availableas a video on YouTube.Developing using C++ is known to be not the easiest language, as many students struggle with the concept of points.To make my life a little bit easier, I implemented a small lightweight unit-testing framework in C++ next to it, so thatI could easily test the more complex things, such as the scene graph or other data structures we had to implement from scratch.We have not been allowed to use any third party library beside ncursesfor the ASCII rendering, so I had to get creative. But in the end, using a close to TDD style of development helped me tofind tiny bugs quick and resolve them efficiently. And all this payed out a lot. In the end, I was the only student whocould finish the entire engine without any of the extra features left out.Any my professor Mark Claypool was more than impressed.Now, he seems to have liked the idea so much that he made it part of this book and course. Based on my UnitTestManager,he now provids a small UTM framework to his students to use.And generally encourages to do unit testing right from the beginning.I’m happy, that my ideas contribute to make this really great and fun course even better." }, { "title": "Developer Interview with PocketPC", "url": "/posts/dev-interview-pocketpc-ch/", "categories": "Projects, Windows", "tags": "interview, windows, windows phone, apps", "date": "2014-06-25 00:00:00 +0200", "snippet": "Recently, I received a message from a Swiss magazine that is specialized for topics around mobile apps and devices,whether I would be interested to participate in a developer interview with them. Of couse, I did not decline this request.You can now find the interview on thePocketPC website.Interview in PocketPC sidebar" }, { "title": "powernAPP is the Best Rated Health & Fitness App in German Windows Phone Store", "url": "/posts/powernapp-best-rated-health-app/", "categories": "Projects, Windows", "tags": "windows, windows phone", "date": "2014-05-17 00:00:00 +0200", "snippet": "To my own surprise, my popular napping app powernAPPmade it to the very top of the Health &amp; Fitnesscategory of the Windows Phone store. Even getting listed before Runtastic. And that at least in Germany,but potentially even a few other countries.Top rated powernAPP in Windows Phone Store highlightsLet’s see for how long it can keep this pole position…" }, { "title": "Apps in Telekom Spotlight", "url": "/posts/apps-in-spotlight/", "categories": "Projects, Windows", "tags": "windows, windows phone", "date": "2014-04-29 00:00:00 +0200", "snippet": "Each Windows Phone from Telekom comes with a few apps pre-installed. One of them is Spotlight, which recommendsa few apps especially for the German audience every week. By coincidence, I noticed that Telekom is listingtwo of my apps in the Spotlight app under the Top Apps category.SpaceScribble (left) and powernAPP (right) in Telekom Spotlight appTranslating the short description provided by the Telekom Spotlight authors:SpaceScribble Spaciges Gekrakel: Highscore-Shooter im Bleistift-LookWhich means something like “Spacy scribble: highscore shooter in pencil style”powernAPP Praktischer kleiner Helfer für kurze NickerchenThat means “Practical little helper for short naps” in English.Great to see that not just the Windows Store, but also other app listings recomment my apps." }, { "title": "Review of SpaceScribble on WPCentral", "url": "/posts/spacescribble-review-wpcentral/", "categories": "Projects, Windows", "tags": "windows, windows phone, game dev, review", "date": "2014-03-06 00:00:00 +0100", "snippet": "Today, I noticed a significant spike in the number of downloads for SpaceScribble.And it just needed a quick search in Google to figure out the root cause for this.SpaceScribble review teaser on WPCentralThe renowned website WPCentral wrote an extensive and very positive reviewabout my game. You can read the entire review calledSpaceScribble, Windows Phone sapce combat the doodleway on their website." }, { "title": "powernAPP Wins Microsoft AppRevolution Competition", "url": "/posts/microsoft-app-revolution-powernapp/", "categories": "Projects, Windows", "tags": "windows, windows phone, microsoft, competition", "date": "2014-01-21 00:00:00 +0100", "snippet": "Once again I participated in the lastest AppRevolution competition by Microsoft Germany. This year’s topic was rather genericand just called “Christmas special”. Just recently, I received the following friendly message by Ann Kristin Bockelmannfrom App Marketing and Developer and Platform Evangelism of Microsoft that I won this years competition. Lieber Benjamin, vielen Dank noch einmal, dass du bei der Microsoft Christmas App Revolution teilgenommen hast.Ich darf dir heute mitteilen, dass du bei unserer Jury-Entscheidung den ersten Preis gewonnen hast: ein Microsoft Surface Pro Tablet sowie ein Developer Support Paket! Bitte schreibe uns noch deine Adresse, damit wir dir deinen Gewinn zuschicken können. Wir freuen uns, wenn du bei der kommenden App Revolution wieder dabei bist! Viele Grüße,dein Microsoft TeamPersonally, I can recommend every Windows Phone app developer to participate at this competition, as there a quite a fewnice gadgets to win, such as smartphones or other hardware. Last year, I won a Microsoft Wedge Touch mouse.The next Microsoft AppRevolution competition is about Education and submission deadline is the 28th of February 2014." }, { "title": "Speed Up Your Windows Phone App", "url": "/posts/speed-up-your-windows-phone-app/", "categories": "Software Engineering, Windows", "tags": "windows, windows phone, performance", "date": "2013-12-06 00:00:00 +0100", "snippet": "You have a Windows Phone app and are not happy about its performance? Well, I had this feeling with a fewof my apps recently. But don’t worry. There are a few simple tweaks you could do to gain significant improvements.Fast app switchingEach Windows Phone app can be in a differnt state based on the app’slifecycle.When the user quits your app or switches to another one, it will either end up in the dormant or tombstoned state. While the firstone means the apps data is still in main memory, the latter one however causes the app to be destroyed to make space for other apps.Consequently, when an app resumes in dormant state then there is no need to reload data from IsolatedStorage, the web or similar.All that data is still available. That’s the reason why this technique is calledfast application switching, as it reduces theloading time when switching between apps. And it’s implementation is rather either, because all you need to do is to check theActivated event of your application whether the e.IsApplicationStatePreserved property is set.if (e.IsApplicationInstancePreserved){ // data is still in memory}else{ // TODO: load data here...}More details about this is available in theMSDN blog.Fast app resumeYou might know this feature from popular apps such as WhatsApp or Facebook. You quit an app from a sub page,but the user ends up on the same page when you start the app once again from the launcher. While this is honestly something thatmight be only interesting for more complex apps with many different pages, it is worth mentioning that this is quite easy toimplement. In a nutshell, all you need to do is to edit the WMAppManifest.xml and adjust the page stack.You can find further implementation details in theWindows Phone Developer Blog.Loaded vs NavigatedTo eventIn the past, I was always a bit puzzled whether it is better to load the apps data in the Loaded or the NavigatedTo event.When looking at examples in the web, it seems that most developers did not think about this too much.This is probably no general rule, but I noticed it can be worth it to load data in the NavigatedTo event.First of all, it is imporatant to know that the NavigatedTo event is fired before Loaded. The latter one is fired afterall control elements have been loaded. And due to the fact that most apps use page transition animations when switching from onepage to another, it can make a significant difference when you already start to load data asynchronously while the animationis in progress. This has the effect that users perceive your app to respond faster.Further optimization techniquesThere are of course many other techniques to optimize your apps performance, such as lazy loading or caching.I can recommend that you look at your app’s performance from a critical perspective. Or even better ask a good friend to beless technically biased. And based on that feedback, think about ways to improve that performance. Is there manybe anythingthat could be done in parallel that is currently done in sequence? Are you loading the same data again and again?Trust me, your users will appreciate that." }, { "title": "250k Downloads in Windows Phone Store", "url": "/posts/250k-downloads-windows-store/", "categories": "Projects, Analytics", "tags": "windows, windows phone, downloads", "date": "2013-10-04 00:00:00 +0200", "snippet": "My apps and games in the Windows Phone store reached the milestone of a quarter million downloads.250k downloads in Dev Center websiteThe main driver is SpaceScribblethat never had less than 1000 downloads per day within the last month. And in total, is was downloaded 145,521 times already.Not bad, right? This high number in downloads is quite easy to explain. At least since August this year, that gameis frequently listed in highlights of the Windows Phone store*. Furthermore, there are 820 user reviews already,with an average global rating of **4.5 out of 5 stars. However, the average rating is very different when looking atdifferent regions individually.The next goal is obviously 500k downloads. In case the number of downloads stays more or less constant, then this should takejust about 6 months. Except I manage to publish another app with similar high number of downloads to speed this up a little." }, { "title": "Augmented Reality with Google Glass", "url": "/posts/augmented-reality-google-glass/", "categories": "University, Abroad", "tags": "university, project, google", "date": "2013-09-18 00:00:00 +0200", "snippet": "During my exchange semester abroad at WPI, I visited an AR coursethat was actually meant for Master’s students about Augmented Reality.In the second lecture, our professor entered the room wearing a Google Glass.Turns out he was one of the few selected people outside of Google to do Beta testing in real life.Wearing an early version of Google GlassThere are pleanty of videos out there to show the vision behind Google Glass.But I’m sure you have heard of it already in some way.Our professor was kind enough that every student of the course could check out Google Glass for a few minutes.Here are my first impressions in a brief: Compared to what is indicated in the videos by Google, it is not a see-through glass but more an extra displaythat thows contextual information. However, you have to actively look to the top-right corner to see it. The availability of apps is still very limited. Google Glass has a touch control on one side. However, I personally think it looked very odd that our professor was constantlyswiping with his hand along his glasses. The voice activation of the glasses is triggered with the words “Hello Glass!”, followed by the action.To take a picture for example, you have to say “Hello Glass, take a picture.”. This voice activation would however be a bittroublesome when there is more than one person wearing a set of Google Glass. The is not voice identifiaction of the user yet. The audio output of the glasses work via bone conduction. This means there are tiny vibration that are transmitted directlyto your inner ear. And that worked surprisingly well. According to our professor, the batteries are charted within 45 minutes, and last about a day." }, { "title": "Three Day Kajak Tour", "url": "/posts/three-day-kajak-tour/", "categories": "Outdoors, Kajak", "tags": "kajak, trip", "date": "2013-07-22 00:00:00 +0200", "snippet": "Due to my upcoming exchange semster to the US, this will be my last semester together with my friend from college.To have one more long lasting memoery, we decided to to a kajak trip together till my hometown.We prepared the Kajaks from rented from the AMH Kajak Club in the early morning, wrote our last exam already wearing oursurfer shorts, and then started our trip right after we handed it in.Kajak tour from Constance to MurgIn total, our trip lasted three days with a distance of about 125km. And it was indeed an outstanding journey.We have been very lucky with the weather. Maybe even a little bit too lucky.To stay over night, we camped once in a clearance next to Stein am Rhein.The second night, we setted up our tent more legally on the camping ground in Hohentengen.It is worth to mention that there are 8 watergates and one waterfall on that route. This means that we had to carryour Kajaks from time to time. Usually not a big deal. However, with all that stuff we had with us this was honstly quiteexhausing.Timo and me carrying our KajaksIn case you ever plan do to something similar, then I would have the following hints for your: Lifejackets: Not just for your own safety, but also for your comfort. I used them as a mat for my feets, or to sit on top. Biking gloves: To ensure you are not getting painful blisters after the first day. Sun blocker: Lots of it. Trust me. I looked like a tomato after that trip. Lots of beverages: At least we ran out of beer more quickly than we planned. Garbage bags: To make sure you don’t leave anything behind. But you can also use it to protect other things to not get wet. Kajak trolly: This is a real lifesaver due to the many times we had to carry the packed kajaks." }, { "title": "Xtext - Your Own Programming Language Here", "url": "/posts/xtext-your-own-language-here/", "categories": "Software Engineering", "tags": "xtext, dsl, eclipse, xtext, xtend, university", "date": "2013-07-03 00:00:00 +0200", "snippet": "Did you ever dream of proposing your own programming language? If so, then Xtextmight be something for you. LANGUAGE ENGINEERING FOR EVERYONE! Xtext is a framework for development of programming languages and domain-specific languages.With Xtext you define your language using a powerful grammar language. As a result you get a full infrastructure,including parser, linker, typechecker, compiler as well as editing support for Eclipse, any editor that supportsthe Language Server Protocol and your favorite web browser.(source)Domain specific languageThis Eclipse IDE plugin enables you to use simplifiedEBNF grammar to define yourDSL that is just right for you. And Xtext helps you do generatetools, parser and and editor syntax highlighting and code completion. This way it allows you to define a DSl with onlylittle effort. Did I get you excited? Then give the short Xtext tutorialsa try. These few minutes are well spent.Code generationFurthermore, you can create a code generator to reduce boilerplate code. This is done via the integrated languageXtend. This language is something in between Java and C#, which however has a slightlymore compact syntax. Xtend can be used to easily generate your boilerplate code for classes, methods, properties or documentationthat usually follow a very similar strucutre.Example code generatorHere is some Xtent code to get an idea how this might look like.grammar org.xtext.de.htwg.ModelGen with org.eclipse.xtext.common.Terminalsgenerate modelGen \"http://www.xtext.org/de/htwg/ModelGen\"ModelGen: 'PACKAGE' name=QualifiedName 'NAME' pluginName=ID elements+=RootElement*;RootElement: PackageDeclaration | Type | Import;AbstractElement: Type | Import;QualifiedName: ID ('.' ID)*;QualifiedNameWithWildcard: QualifiedName '.*'?;Type: Typedef | Interface;Typedef: 'type' name=ID;PackageDeclaration: 'package' name=QualifiedName '{' elements+=AbstractElement* '}';Import: 'import' importedNamespace = QualifiedNameWithWildcard;Interface: 'interface' name=ID '{' methods+=Method* '}';Method: 'method' name=ID '('(params+=Parameter (',' params+=Parameter)*)?')' ':' type=[Type | QualifiedName];Parameter: name=ID ':' type= [Type | QualifiedName];Xtend then generates various artefacts such as the EMF model based on the EBNF grammar above to create our generator.An example of our DSL could look like to following.PACKAGE de.htwg.seapal.personNAME Persontype voidtype Stringtype booleantype longpackage model { interface IDatabase { method save(data: String): void method delete(id: long): boolean method get(id: long): String method close(): void }}The in Xtend integrated templating engine can then be used to generate your code. This enables you to generate codein a form that is much easier to grasp compared to using a StringBuilder or similar. Just check out the following code snippet.override void doGenerate(Resource resource, IFileSystemAccess fsa) { // Find root package name for (e: resource.allContents.toIterable.filter(typeof(Plugin))) { rootPackage = e.fullyQualifiedName; pluginName = e.name.toLowerCase().toFirstUpper(); } // Generate interfaces for (e: resource.allContents.toIterable.filter(typeof(Interface))) { fsa.generateFile( e.fullyQualifiedName.toString(\"/\") + \".java\", e.compileInterface) } // …}def compileInterface(Interface iface)''' «IF iface.eContainer != null» package «iface.eContainer.fullyQualifiedName»; «FOR i:iface.eContainer.eContents.filter(typeof(Import))» import «rootPackage».«i.importedNamespace»; «ENDFOR» «ENDIF» /** * Generated model interface «iface.name». * @author TODO * @version TODO */ public interface «iface.name» { «FOR m:iface.methods» «m.compileMethodInterface» «ENDFOR» }'''def compileMethodInterface(Method p) ''' /** * TODO: Method description... * «IF p.params != null»@param TODO: describle all parameters...«ENDIF» * «IF !p.type.fullyQualifiedName.toString.equals(\"void\")»@return TODO: Return value description...«ENDIF» */ public «p.type.fullyQualifiedName.lastSegment» «p.name.toFirstLower»(«FOR prm:p.params SEPARATOR \", \"»«prm.type.fullyQualifiedName.lastSegment» «prm.name»«ENDFOR»);'''And that’s more or less it. If you now start a second Eclipse IDE instance and define a /src-gen folder, then the code is automatically generateddepending on the textual model." }, { "title": "100k Downloads in Windows Phone Store", "url": "/posts/100k-downloads-windows-store/", "categories": "Projects, Analytics", "tags": "windows, windows phone, downloads", "date": "2013-05-24 00:00:00 +0200", "snippet": "My apps and games in the Windows Phone store reached a first milestone of 100,000 downloads.100k downloads in Windows Phone storeThe peaks in the chart above before 2013 are easy to explain. Whenever a new app was released, this app was then listedin the New Releases (“Neu und Angesagt” in German) section of the Windows Phone store at the very top.However, such a peak is not visible for ScribbleHunterwhich was released on April 2013. It looks like the previous naive ranking algorithm of listed any new app at the very frontgot changed in the meantime. Honestly speaking, that was just a matter of time.The following table lists the detailed number of downloads for each app. App / Game Total downloads SpaceScribble 50,810 AstropiXX 29,454 SpacepiXX 17,071 ScribbleHunter 3,009 VaderpiXX 2,514 seeMENSA 424 ScribbleHunter Pro 147 Total 103,429 " }, { "title": "Microsoft AppRevolution Competition", "url": "/posts/microsoft-app-revolution-live-tile/", "categories": "Projects, Windows", "tags": "windows, windows phone, microsoft, competition", "date": "2013-04-21 00:00:00 +0200", "snippet": "It’s worth checking out the Microsoft TechStudents website from time to time. There, you can find small challenges that can bemore than worth it for indie developers like me.At the moment for example, there is a competition calledAppRevolution with the topic Live Tilefor any Windows Phone 8 and Windows 8 game to qualify for it. Submission deadline is the 2nd of May and the app needs to bepublically available in the Windows Store that day.Fortunately for me, both of my games VaderpiXXand AstropiXX that I ported to Windows 8using MonoGame fulfills all required criteria. Obviously, I’m gonna give it a short.Thank you very much to my friend Patrick Mutter, who is ourMicrosoft Student Partner atHochschule Konstanz University of Applied Sciences for making me aware of this competition.Update 2013/05/22:I just got an Email by Kai Jäger, Technical Evangelist of Microsoft Germany that I won a secondary material prize,which is a Microsoft Wedge Touch mouse." }, { "title": "Automatic Viewport Scaling in Windows 8 Apps Using MonoGame", "url": "/posts/auto-scaling-mono-game-windows8/", "categories": "Software Engineering, Games", "tags": "csharp, windows, monogame, game dev", "date": "2013-04-11 00:00:00 +0200", "snippet": "As posted recently, I started to port a few of my games to Windwos 8 using MonoGame.And I’m slowy getting there to submit my first game to the Window 8 Store. However, I had quite some troubles first regardingthe adjustment of the viewport when changing the screens resolution. And after reading through several forums, it looks likeothers have been struggling as well. A few individuals offered alternative forks of MonoGame that have resolved this kindof problem built-in. Others suggested to create a copy and do some manual changes in OpenTK, which is anopen source C# wrapper for OpenGL, OpenAL and OpenCL. However, I decided to not use any manually modified version of any of theselibraries, because otherwise it will be hard upgrade that dependency at some point.Anyways, I managed to solve that problem at some point. The following snippet shows the most important bits.protected override void Initialize(){ graphics.IsFullScreen = true; graphics.PreferredBackBufferHeight = 480; graphics.PreferredBackBufferWidth = 800; // … graphics.ApplyChanges(); ApplicationViewChanged += Game_ApplicationViewChanged; this.Window.ClientSizeChanged += Window_ClientSizeChanged; handleScreenViewState(); base.Initialize();}void Window_ClientSizeChanged(object sender, EventArgs e){ this.GraphicsDevice.Viewport = new Viewport(0, 0, 800, 480); graphics.PreferredBackBufferHeight = 480; graphics.PreferredBackBufferWidth = 800; graphics.ApplyChanges();}void Game_ApplicationViewChanged(object sender, ViewStateChangedEventArgs e){ handleScreenViewState();}The most important part is the ClientSizeChanged callback of the Window class. In particular for Windows 8 Desktop games,also the ApplicationViewChanged callback of the Game class plays an important role here, because this enabled to reacton chages of the ViewState, such as when the app entered Snapped Mode.By explicitly setting the back buffer and applying the changes once again in the ClientSizeChanged helps to end up withthe same behavior you might be familiar with in XNA. And the screen scalesautomatically when the viewport or screens aspect ratio changed. For whatever reason, MonoGame performs an unexpected changeof the back buffer and the viewport, thus causing the video output to be incorrect. Consquently, manually resetting thepreferred back buffer and viewport sizes resolves this problem." }, { "title": "Porting Windows 8 Games Using MonoGame", "url": "/posts/porting-games-using-mono-game-windows8/", "categories": "Software Engineering, Games", "tags": "windows, monogame, game dev, csharp", "date": "2013-04-08 00:00:00 +0200", "snippet": "You might have heard already of Mono. It’s more or less an open source implementation ofthe .NET Framework and allows to bring your apps developed in C# to other platforms. And beside that, there is alsoa free implementation of XNA game, called MonoGame, which is a framework for creating powerfulcross-platform games. All my Windows Phone 8 games are based on XNA. And with the power of MonoGame, I believe it might beworth a try to bring these games to Windows 8 PC.I honestly just started a few days ago. But so far, I can say that things are working better than expected. It just took meabout 2 hours to have a running version of VaderpiXXrunning on my Windows 8 laptop.VaderpiXX running with MonoGame on my X220 Windows 8 laptopOf course, the devil is in the details. That game was both a touch and accelerometer controlled game. And the latter istypically not available on most Windows 8 devices. So there are various adjustments of the game required before its readyto be tested and published.I also had a quick look into how to port the game to Android or iOS. However, this requires an Indie license ofXamarin that is unfortunately not free.I’m pretty excited to bring my games to Windows 8. Many of my friends have no Windows Phone, but a Windows 8 PC or laptop.So this might be the easiest way to enable them to play them, too." }, { "title": "CeBIT 2013 in Hannover", "url": "/posts/cebit-2013/", "categories": "Events, IT", "tags": "conference, cebit, trip", "date": "2013-03-09 00:00:00 +0100", "snippet": "With a little bit of luck, we ended up with 3 free tickets for CeBIT 2013 sponsored by our university in Constance.We spent an entire weekend there and had planty of time to check out everything this gigantic exhibition had to offer.Demonstration about virtual realityWe have seen so many things that it is hard to write about everything here. I will therefore just add a few picturesto share some impressions of it.Finals of the Intel World Championship in Starcraft 2On our way back, we stopped for one night in Frankfurt. It was my first time ever in that city. And we took the chanceto enjoy the view from the highest viewing point at Main Tower.Panorama from Frankfurt’s Main Tower" }, { "title": "Rocking the Ortstock", "url": "/posts/rocking-ortstock/", "categories": "Events, IT", "tags": "conference, cebit, trip", "date": "2012-09-11 00:00:00 +0200", "snippet": "Yesterday, together with some friends we drove to Biblisthal in Switzerland to hike theOrtstock peak, which is located at an elevation of 2,717 m (or 8,914 ft)on the border between the cantons of Schwyz and Glarus. Due to the sunny weekend weather, it was not really hard to get themotiviation need for this. And what started as a slow-paced hike ended up in a strenuous effort.Halfway to the Ortstock’s peakHere are some fun facts about our hike: Total distance: 19 km Altitude: more than 1,300m each way Duration: about 9 hours (incl. a few breaks and enjoyful peak beer) Energy consumption: about 3,800 kcalsOrtstock’s summit crossThis was honestly my first hike in the Swiss Alps.And it was a really amazing experience. Spending some time in such an idyllic and untouched naturereally helps to free your mind." } ]
